
依赖：
<dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-core</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- 检索关键字高亮显示 -->
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-highlighter -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-highlighter</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- 与查询比较的高性能单文档索引 高亮显示需要此jar -->
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-memory -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-memory</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-queryparser -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-queryparser</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-demo -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-demo</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- 一般分词器，适用于英文分词 -->
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-common -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-analyzers-common</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!-- 中文分词器 -->
    <!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-smartcn -->
    <dependency>
      <groupId>org.apache.lucene</groupId>
      <artifactId>lucene-analyzers-smartcn</artifactId>
      <version>7.4.0</version>
    </dependency>
    <!--编码转换 -->
    <!-- https://mvnrepository.com/artifact/commons-io/commons-io -->
    <dependency>
      <groupId>commons-io</groupId>
      <artifactId>commons-io</artifactId>
      <version>2.0</version>
    </dependency>

    <dependency>
      <groupId>org.wltea.ik-analyzer</groupId>
      <artifactId>ik-analyzer</artifactId>
      <version>3.2.8</version>
    </dependency>
===================过程
//1 创建文档对象
//2 创建存储目录
//3 创建分词器
//4 根据分词器创建索引写入器的配置对象
//5 根据配置对象和存储目录创建索引写入器对象
//6 将文档交给索引写入器
//7 提交
//8 关闭

 // 准备中文分词器
IKAnalyzer analyzer = new IKAnalyzer();
//创建存储目录
Directory index = new RAMDirectory();
//创建索引写入器的配置对象
IndexWriterConfig config = new IndexWriterConfig(analyzer);
//根据配置创建索引写入器对象
IndexWriter writer = new IndexWriter(index, config);
//文档字符数据写入存储目录(可以添加多个字段数据)，关闭
Document doc = new Document();
doc.add(new TextField("字段名", "数据字符串...", Field.Store.YES));
writer.addDocument(doc);
writer.close();

//查询器，关键字为"护眼带光源"，并指定搜索含有该字段名的Document
String keyword = "护眼带光源";
Query query = new QueryParser("字段名", analyzer).parse(keyword);

//搜索
IndexReader reader = DirectoryReader.open(index);	//创建索引 reade
IndexSearcher searcher = new IndexSearcher(reader);	//基于 reader 创建搜索器
int numberPerPage = 1000;				//指定每页要显示1000条数据
ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs;	//执行搜索，SoreDoc由匹配分、文档的id封装成的对象

//遍历结果
for (int i = 0; i < hits.length; ++i) {
    ScoreDoc scoreDoc= hits[i];
    int docId = scoreDoc.doc;
    Document d = searcher.doc(docId);				//根据ID获取对应的文档
    List<IndexableField> fields = d.getFields();		//获取文档的所有字段

    for (IndexableField f : fields) {
        System.out.println("\t" + d.get(f.name()));		//根据字段获取文档对应字段的字符数据
    }
}

===============================分词器
IKAnalyzer analyzer = new IKAnalyzer();
TokenStream ts= analyzer.tokenStream("name", "护眼带光源");
ts.reset();
while(ts.incrementToken()){
    System.out.println(ts.reflectAsString(false));
}

输出结果为：
加载扩展词典：ext.dic（告诉它这些词是完整有语义的词，不要再做切分，放在resource下）
加载扩展停止词典：stopword.dic（中文分词的时候会忽略它们，如 “的”、“地”、“得” 等）
term=护眼,bytes=[e6 8a a4 e7 9c bc],startOffset=0,endOffset=2,positionIncrement=1,positionLength=1,type=CN_WORD,termFrequency=1
term=带,bytes=[e5 b8 a6],startOffset=2,endOffset=3,positionIncrement=1,positionLength=1,type=CN_CHAR,termFrequency=1
term=光源,bytes=[e5 85 89 e6 ba 90],startOffset=3,endOffset=5,positionIncrement=1,positionLength=1,type=CN_WORD,termFrequency=1

===========================亮度显示
//设置关键字首尾添加的内容"<span style='color:red'>", "</span>"
SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter("<span style='color:red'>", "</span>");
//根据上面和搜索的关键字设置提亮对象highlighter
Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query));

//给要搜索结果的完整字符串数据分词
TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name())));
//提亮对象highlighter给完整字符串数据中的关键字提亮
String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name()));    

==========================删除索引
//删除id=51173的数据
IndexWriterConfig config = new IndexWriterConfig(analyzer);
IndexWriter indexWriter = new IndexWriter(index, config);
indexWriter.deleteDocuments(new Term("id", "51173"));	//id为字段名，51173为词，删除id字段含有51173词的doc
indexWriter.commit();
indexWriter.close();

其他：
DeleteDocuments(Query query):根据Query条件来删除单个或多个Document
DeleteDocuments(Query[] queries):根据Query条件来删除单个或多个Document
DeleteDocuments(Term term):根据Term来删除单个或多个Document
DeleteDocuments(Term[] terms):根据Term来删除单个或多个Document
DeleteAll():删除所有的Document


==========================删除索引
// 更新索引
IndexWriterConfig config = new IndexWriterConfig(analyzer);
IndexWriter indexWriter = new IndexWriter(index, config);

Document doc = new Document();
doc.add(new TextField("id", "51173", Field.Store.YES));
doc.add(new TextField("name", "神鞭，鞭没了，神还在", Field.Store.YES));
doc.add(new TextField("category", "道具", Field.Store.YES));
doc.add(new TextField("price", "998", Field.Store.YES));
doc.add(new TextField("place", "南海群岛", Field.Store.YES));
doc.add(new TextField("code", "888888", Field.Store.YES));

indexWriter.updateDocument(new Term("id", "51173"), doc );
indexWriter.commit();
indexWriter.close();
